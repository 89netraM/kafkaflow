"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[187],{3905:(e,t,r)=>{r.d(t,{Zo:()=>d,kt:()=>m});var a=r(7294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function s(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?s(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):s(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function o(e,t){if(null==e)return{};var r,a,n=function(e,t){if(null==e)return{};var r,a,n={},s=Object.keys(e);for(a=0;a<s.length;a++)r=s[a],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(a=0;a<s.length;a++)r=s[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var l=a.createContext({}),p=function(e){var t=a.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},d=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var r=e.components,n=e.mdxType,s=e.originalType,l=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),u=p(r),m=n,g=u["".concat(l,".").concat(m)]||u[m]||c[m]||s;return r?a.createElement(g,i(i({ref:t},d),{},{components:r})):a.createElement(g,i({ref:t},d))}));function m(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var s=r.length,i=new Array(s);i[0]=u;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o.mdxType="string"==typeof e?e:n,i[1]=o;for(var p=2;p<s;p++)i[p]=r[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,r)}u.displayName="MDXCreateElement"},6814:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>s,metadata:()=>o,toc:()=>p});var a=r(7462),n=(r(7294),r(3905));const s={sidebar_position:11},i="Serializer Middleware",o={unversionedId:"guides/serializer-middleware",id:"guides/serializer-middleware",title:"Serializer Middleware",description:"It's a middleware used to serialize and deserialize messages. Install the KafkaFlow.Serializer package and add the AddSerializer extension method to your producer/consumer middlewares to use it. The method can receive two classes as generic arguments. The first one must implement the IMessageSerializer interface. The second one is optional and must implement the IMessageTypeResolver interface, if the parameter is not passed then the DefaultTypeResolver will be used. Both classes can be passed as a normal argument through a factory method too. For topics that have just one message type use the AddSingleTypeSerializer method.",source:"@site/docs/guides/serializer-middleware.md",sourceDirName:"guides",slug:"/guides/serializer-middleware",permalink:"/docs/guides/serializer-middleware",draft:!1,editUrl:"https://github.com/farfetch/kafkaflow/tree/master/website/docs/guides/serializer-middleware.md",tags:[],version:"current",sidebarPosition:11,frontMatter:{sidebar_position:11},sidebar:"tutorialSidebar",previous:{title:"Producers",permalink:"/docs/guides/producers"},next:{title:"Typed Handler Middleware",permalink:"/docs/guides/typed-handler-middleware"}},l={},p=[{value:"These packages provide some commonly used serialization algorithms",id:"these-packages-provide-some-commonly-used-serialization-algorithms",level:4},{value:"Schema Registry support",id:"schema-registry-support",level:2},{value:"Message Type Resolver",id:"message-type-resolver",level:2}],d={toc:p};function c(e){let{components:t,...r}=e;return(0,n.kt)("wrapper",(0,a.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"serializer-middleware"},"Serializer Middleware"),(0,n.kt)("p",null,"It's a middleware used to serialize and deserialize messages. Install the ",(0,n.kt)("a",{parentName:"p",href:"https://www.nuget.org/packages/KafkaFlow.Serializer/"},"KafkaFlow.Serializer")," package and add the ",(0,n.kt)("inlineCode",{parentName:"p"},"AddSerializer")," extension method to your producer/consumer middlewares to use it. The method can receive two classes as generic arguments. The first one must implement the ",(0,n.kt)("inlineCode",{parentName:"p"},"IMessageSerializer")," interface. The second one ",(0,n.kt)("strong",{parentName:"p"},"is optional")," and must implement the ",(0,n.kt)("inlineCode",{parentName:"p"},"IMessageTypeResolver")," interface, if the parameter is not passed then the ",(0,n.kt)("inlineCode",{parentName:"p"},"DefaultTypeResolver")," will be used. Both classes can be passed as a normal argument through a factory method too. For topics that have just one message type use the ",(0,n.kt)("inlineCode",{parentName:"p"},"AddSingleTypeSerializer")," method."),(0,n.kt)("h4",{id:"these-packages-provide-some-commonly-used-serialization-algorithms"},"These packages provide some commonly used serialization algorithms"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.nuget.org/packages/KafkaFlow.Serializer.ProtobufNet/"},"KafkaFlow.Serializer.ProtoBufNet")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.nuget.org/packages/KafkaFlow.Serializer.JsonCore/"},"KafkaFlow.Serializer.JsonCore")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.nuget.org/packages/KafkaFlow.Serializer.NewtonsoftJson/"},"KafkaFlow.Serializer.NewtonsoftJson"))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-csharp"},'public class Startup\n{\n    public void ConfigureServices(IServiceCollection services)\n    {\n        services.AddKafka(kafka => kafka\n            .AddCluster(cluster => cluster\n                .WithBrokers(new[] { "localhost:9092" })\n                .AddProducer<ProductEventsProducer>(producer => producer\n                    ...\n                    .AddMiddlewares(middlewares => middleware\n                        ...\n                        .AddSerializer<JsonMessageSerializer>() // Using the DefaultMessageTypeResolver\n                        // or\n                        .AddSerializer<JsonMessageSerializer, YourTypeResolver>()\n                        // or\n                        .AddSerializer(\n                            resolver => new JsonMessageSerializer(...),\n                            resolver => new YourTypeResolver(...))\n                        // or\n                        .AddSingleTypeSerializer<JsonMessageSerializer, YourMessageType>()\n                        // or\n                        .AddSingleTypeSerializer<YourMessageType>(resolver => new JsonMessageSerializer(...))\n                        ...\n                    )\n                )\n            )\n        );\n    }\n}\n')),(0,n.kt)("h2",{id:"schema-registry-support"},"Schema Registry support"),(0,n.kt)("p",null,"Serializer middlewares can be used along with schema registry allowing the evolution of schemas according to the configured compatibility setting."),(0,n.kt)("p",null,"Install the ",(0,n.kt)("a",{parentName:"p",href:"https://www.nuget.org/packages/KafkaFlow.SchemaRegistry/"},"KafkaFlow.SchemaRegistry")," package, configure the schema registry broker, and use one of the following packages to use all the schema registry integration features."),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.nuget.org/packages/KafkaFlow.Serializer.SchemaRegistry.ConfluentJson/"},"KafkaFlow.Serializer.SchemaRegistry.ConfluentJson")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.nuget.org/packages/KafkaFlow.Serializer.SchemaRegistry.ConfluentAvro/"},"KafkaFlow.Serializer.SchemaRegistry.ConfluentAvro")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.nuget.org/packages/KafkaFlow.Serializer.ConfluentProtobuf/"},"KafkaFlow.Serializer.SchemaRegistry.ConfluentProtobuf"))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-csharp"},'public class Startup\n{\n    public void ConfigureServices(IServiceCollection services)\n    {\n        services.AddKafka(\n            kafka => kafka\n                .AddCluster(\n                    cluster => cluster\n                        .WithBrokers(new[] { "localhost:9092" })\n                        .WithSchemaRegistry(config => config.Url = "localhost:8081")\n                        .AddProducer(\n                            ...\n                            .AddMiddlewares(middlewares => \n                                    middlewares.AddSchemaRegistryAvroSerializer(new AvroSerializerConfig{ SubjectNameStrategy = SubjectNameStrategy.TopicRecord })\n                        )\n                       .AddConsumer(\n                            ...\n                            .AddMiddlewares(middlewares => middlewares.AddSchemaRegistryAvroSerializer()\n                        )\n                    )\n            );\n    }\n}\n')),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://www.nuget.org/packages/KafkaFlow.Serializer.SchemaRegistry.ConfluentAvro/"},"ConfluentAvro")," and ",(0,n.kt)("a",{parentName:"p",href:"https://www.nuget.org/packages/KafkaFlow.Serializer.ConfluentProtobuf/"},"ConfluentProtobuf")," type resolvers can support multiple types per topic however, due to json serialization format used by ",(0,n.kt)("a",{parentName:"p",href:"https://docs.confluent.io/platform/current/clients/confluent-kafka-dotnet/_site/api/Confluent.SchemaRegistry.Serdes.JsonSerializer-1.html"},"confluent-kafka-dotnet"),", ",(0,n.kt)("a",{parentName:"p",href:"https://www.nuget.org/packages/KafkaFlow.Serializer.SchemaRegistry.ConfluentJson/"},"ConfluentJson")," type resolver can only resolve a single type of message per topic. "),(0,n.kt)("p",null,"In order to be able to publish multiple type messages per topic, ",(0,n.kt)("inlineCode",{parentName:"p"},"SubjectNameStrategy.Record")," or ",(0,n.kt)("inlineCode",{parentName:"p"},"SubjectNameStrategy.TopicRecord")," must be used. "),(0,n.kt)("p",null,"You can see a detailed explanation ",(0,n.kt)("a",{parentName:"p",href:"https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#subject-name-strategy"},"here"),"."),(0,n.kt)("h2",{id:"message-type-resolver"},"Message Type Resolver"),(0,n.kt)("p",null,"A type resolver is needed to instruct the middleware where to find the destination message type in the message metadata when consuming and where to store it when producing. The framework has the ",(0,n.kt)("inlineCode",{parentName:"p"},"DefaultTypeResolver")," that will be used omitting the second type parameter in the ",(0,n.kt)("inlineCode",{parentName:"p"},"AddSerializer")," method. You can create your own implementation of ",(0,n.kt)("inlineCode",{parentName:"p"},"IMessageTypeResolver")," to allow communication with other frameworks."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-csharp"},'public class SampleMessageTypeResolver : IMessageTypeResolver\n{\n    private const string MessageType = "MessageType";\n\n    public Type OnConsume(IMessageContext context)\n    {\n        var typeName = context.Headers.GetString(MessageType);\n\n        return Type.GetType(typeName);\n    }\n\n    public void OnProduce(IMessageContext context)\n    {\n        context.Headers.SetString(\n            MessageType,\n            $"{context.Message.GetType().FullName}, {context.Message.GetType().Assembly.GetName().Name}");\n    }\n}\n')))}c.isMDXComponent=!0}}]);